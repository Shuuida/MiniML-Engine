name: CI - MiniML Embedded Pipeline

on:
  push:
    branches: [ "main", "master", "develop" ]
  pull_request:
    branches: [ "main", "master" ]
  workflow_dispatch:
    inputs:
      target_arch:
        description: 'Arquitectura objetivo (arm/xtensa)'
        required: false
        default: 'arm'
      test_quantization:
        description: 'Probar cuantificaci√≥n (true/false)'
        required: false
        default: 'true'

jobs:
  # ------------------------------------------------------------------
  # JOB 1: Python Logic & Unit Tests
  tests:
    name: üêç Core Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install MiniML & Deps
        run: |
          pip install --upgrade pip
          pip install pytest
          pip install -e .
      
      - name: Verify Package Installation
        run: |
          python -c "import miniml; import estimators; import adapters; print('‚úì All packages imported successfully')"
      
      - name: Run Tests
        run: |
          pytest -v --junitxml=test-report.xml tests/
      
      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: test-report.xml

  # ------------------------------------------------------------------
  # JOB 2: Embedded ML Training & C Code Generation
  build-firmware:
    name: ‚öôÔ∏è Build Firmware (${{ inputs.target_arch || 'arm' }})
    needs: tests
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Toolchain
        id: toolchain
        run: |
          ARCH=${{ inputs.target_arch || 'arm' }}
          echo "Setting up for $ARCH..."
          
          if [ "$ARCH" == "arm" ]; then
            sudo apt-get update && sudo apt-get install -y gcc-arm-none-eabi
            echo "compiler=arm-none-eabi-gcc" >> $GITHUB_ENV
            echo "cflags=-mcpu=cortex-m4 -mthumb -mfloat-abi=hard -mfpu=fpv4-sp-d16 -Wall -Werror" >> $GITHUB_ENV
          elif [ "$ARCH" == "xtensa" ]; then
            echo "Assuming Xtensa toolchain is pre-installed on self-hosted runner."
            echo "compiler=xtensa-esp32-elf-gcc" >> $GITHUB_ENV
            echo "cflags=-Wall -Werror" >> $GITHUB_ENV
          else
            echo "compiler=gcc" >> $GITHUB_ENV
            echo "cflags=-Wall -Werror" >> $GITHUB_ENV
          fi

      - name: Install MiniML
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - run: pip install .

      - name: Generate Embedded ML Models (Realistic Scenarios)
        run: |
          mkdir -p build/generated
          
          cat <<'PYEOF' > generate_embedded_models.py
          """
          Genera modelos ML realistas para casos de uso embebidos:
          1. Neural Network con cuantificaci√≥n (XOR - caso cl√°sico)
          2. Decision Tree (clasificaci√≥n simple)
          3. Linear Model (regresi√≥n para sensores)
          """
          import miniml
          import json
          import os
          
          # ============================================
          # CASO 1: Neural Network con Cuantificaci√≥n
          # ============================================
          # Dataset XOR: Caso cl√°sico para validar NN en embebido
          xor_dataset = [
              [0.0, 0.0, 0],
              [0.0, 1.0, 1],
              [1.0, 0.0, 1],
              [1.0, 1.0, 0]
          ]
          
          print("[1/3] Entrenando Neural Network (XOR) con cuantificaci√≥n...")
          nn_result = miniml.train_pipeline(
              model_name="nn_xor_embedded",
              dataset=xor_dataset,
              model_type="neural_network",
              params={
                  "n_inputs": 2,
                  "n_hidden": 4,
                  "n_outputs": 1,
                  "epochs": 2000,
                  "learning_rate": 0.1,
                  "seed": 42
              },
              scaling="minmax"  # Escalado para normalizar inputs
          )
          
          # Validar que act_scales se calcularon (esencial para cuantificaci√≥n)
          model_nn = nn_result['model']
          if not hasattr(model_nn, 'act_scales') or not model_nn.act_scales:
              raise RuntimeError("act_scales no se calcularon - cuantificaci√≥n fallar√°")
          
          print(f"   ‚úì act_scales: {model_nn.act_scales}")
          
          # Exportar c√≥digo C cuantificado
          nn_code = miniml.export_to_c("nn_xor_embedded")
          with open("build/generated/nn_xor_quantized.h", "w") as f:
              f.write(nn_code)
          print("   ‚úì C√≥digo C generado: nn_xor_quantized.h")
          
          # ============================================
          # CASO 2: Decision Tree (Clasificaci√≥n)
          # ============================================
          # Dataset simple para clasificaci√≥n binaria (ej: detecci√≥n de anomal√≠as)
          tree_dataset = [
              [0.1, 0.2, 0],
              [0.3, 0.4, 0],
              [0.7, 0.8, 1],
              [0.9, 0.95, 1]
          ]
          
          print("[2/3] Entrenando Decision Tree...")
          miniml.train_pipeline(
              model_name="dt_classifier_embedded",
              dataset=tree_dataset,
              model_type="DecisionTreeClassifier",
              params={"max_depth": 3},
              scaling="minmax"
          )
          
          dt_code = miniml.export_to_c("dt_classifier_embedded")
          with open("build/generated/dt_classifier.h", "w") as f:
              f.write(dt_code)
          print("   ‚úì C√≥digo C generado: dt_classifier.h")
          
          # ============================================
          # CASO 3: Linear Regression (Sensor Data)
          # ============================================
          # Dataset de regresi√≥n (ej: temperatura vs voltaje)
          linear_dataset = [
              [0.0, 20.0],
              [1.0, 22.5],
              [2.0, 25.0],
              [3.0, 27.5],
              [4.0, 30.0]
          ]
          
          print("[3/3] Entrenando Linear Model (regresi√≥n)...")
          miniml.train_pipeline(
              model_name="linear_sensor_embedded",
              dataset=linear_dataset,
              model_type="linear_regression",
              params={"learning_rate": 0.01, "epochs": 100},
              scaling="standard"
          )
          
          linear_code = miniml.export_to_c("linear_sensor_embedded")
          with open("build/generated/linear_sensor.h", "w") as f:
              f.write(linear_code)
          print("   ‚úì C√≥digo C generado: linear_sensor.h")
          
          # ============================================
          # Validaci√≥n: Verificar caracter√≠sticas embebidas
          # ============================================
          print("\n[VALIDACI√ìN] Verificando caracter√≠sticas embebidas...")
          
          # Verificar que el c√≥digo NN tiene cuantificaci√≥n
          with open("build/generated/nn_xor_quantized.h", "r") as f:
              nn_content = f.read()
              
          checks = {
              "int8_t": "Pesos cuantificados a int8" in nn_content or "int8_t" in nn_content,
              "PROGMEM": "PROGMEM" in nn_content or "const" in nn_content,
              "CMSIS": "CMSIS" in nn_content or "arm_" in nn_content or "predict_int8" in nn_content,
              "Scaler": "preprocess" in nn_content.lower() or "scaler" in nn_content.lower()
          }
          
          for check, passed in checks.items():
              status = "‚úì" if passed else "‚úó"
              print(f"   {status} {check}: {'OK' if passed else 'FALTA'}")
          
          if not all(checks.values()):
              print("   ‚ö†Ô∏è  Algunas caracter√≠sticas embebidas no se detectaron")
          
          print("\n[COMPLETADO] Todos los modelos generados exitosamente")
          PYEOF
          
          python generate_embedded_models.py

      - name: Compile C Artifacts (Syntax & Embedded Checks)
        run: |
          echo "Compilando modelos generados con $compiler..."
          echo "Flags: $cflags"
          
          # Compilar cada modelo generado
          models=("nn_xor_quantized.h" "dt_classifier.h" "linear_sensor.h")
          
          for model in "${models[@]}"; do
            if [ -f "build/generated/$model" ]; then
              echo "Compilando $model..."
              # Extraer solo el c√≥digo C (sin comentarios de header si es .h)
              # Crear un archivo temporal .c para compilar
              temp_c="build/generated/${model%.h}_temp.c"
              
              # Si el archivo es .h, necesitamos crear un wrapper .c
              cat <<CEOF > "$temp_c"
          #include <stdint.h>
          #include <math.h>
          #ifdef __AVR__
          #include <avr/pgmspace.h>
          #endif
          
          // Incluir el modelo generado
          #include "${model}"
          
          // Funci√≥n dummy para evitar linker errors
          int main() { return 0; }
          CEOF
              
              # Compilar con flags embebidos
              $compiler $cflags -c "$temp_c" -o "${temp_c%.c}.o" || {
                echo "‚ùå Error compilando $model"
                exit 1
              }
              echo "‚úì $model compilado exitosamente"
            else
              echo "‚ö†Ô∏è  $model no encontrado"
            fi
          done
          
          echo "‚úÖ Todos los modelos compilaron correctamente"

      - name: Validate Embedded Features
        run: |
          echo "Validando caracter√≠sticas espec√≠ficas de embebido..."
          
          # Verificar que los archivos generados tienen caracter√≠sticas embebidas
          if [ -f "build/generated/nn_xor_quantized.h" ]; then
            echo "Verificando nn_xor_quantized.h..."
            
            # Verificar cuantificaci√≥n
            if grep -q "int8_t" build/generated/nn_xor_quantized.h; then
              echo "  ‚úì Contiene cuantificaci√≥n int8"
            else
              echo "  ‚úó No se detect√≥ cuantificaci√≥n int8"
              exit 1
            fi
            
            # Verificar que no usa float64 o double (solo float32)
            if grep -q "double\|float64" build/generated/nn_xor_quantized.h; then
              echo "  ‚ö†Ô∏è  Advertencia: Usa double/float64 (no ideal para embebido)"
            fi
            
            # Verificar tama√±o razonable (no deber√≠a ser enorme)
            size=$(wc -c < build/generated/nn_xor_quantized.h)
            if [ $size -lt 100000 ]; then
              echo "  ‚úì Tama√±o razonable: ${size} bytes"
            else
              echo "  ‚ö†Ô∏è  Tama√±o grande: ${size} bytes"
            fi
          fi

      - name: Upload Binary Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: firmware-build-${{ inputs.target_arch || 'arm' }}
          path: build/generated/
          retention-days: 7

  # ------------------------------------------------------------------
  # JOB 3: Benchmark & Performance Metrics (Opcional)
  benchmark:
    name: üìä Performance Benchmarks
    needs: build-firmware
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || contains(github.event.head_commit.message, '[benchmark]')
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - run: pip install .
      
      - name: Run Embedded Benchmarks
        run: |
          cat <<'PYEOF' > benchmark_embedded.py
          import miniml
          import time
          
          # Benchmark: Tiempo de entrenamiento y tama√±o de modelo
          xor_data = [[0.0, 0.0, 0], [0.0, 1.0, 1], [1.0, 0.0, 1], [1.0, 1.0, 0]]
          
          print("=== Benchmark: Neural Network Embebido ===\n")
          
          # Entrenamiento
          start = time.time()
          result = miniml.train_pipeline(
              "bench_nn", xor_data, "neural_network",
              params={"n_inputs": 2, "n_hidden": 4, "n_outputs": 1, "epochs": 2000},
              scaling="minmax"
          )
          train_time = time.time() - start
          
          # Exportaci√≥n
          start = time.time()
          c_code = miniml.export_to_c("bench_nn")
          export_time = time.time() - start
          
          # M√©tricas
          model = result['model']
          code_size = len(c_code)
          
          print(f"Tiempo de entrenamiento: {train_time:.3f}s")
          print(f"Tiempo de exportaci√≥n: {export_time:.3f}s")
          print(f"Tama√±o del c√≥digo C: {code_size} bytes")
          print(f"act_scales: {getattr(model, 'act_scales', 'N/A')}")
          print(f"Cuantificado: {getattr(model, 'quantized', False)}")
          PYEOF
          
          python benchmark_embedded.py
